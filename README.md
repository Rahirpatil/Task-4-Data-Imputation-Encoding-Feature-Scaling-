# ğŸ§  Task 4: Data Imputation, Encoding & Feature Scaling â€“ Internship Project

This notebook is the fourth task of my Artificial Intelligence internship at iGAP Technologies. The objective of this task was to preprocess a dataset by handling missing values, converting categorical features into numerical form, scaling features, and splitting the data for model training. These are foundational steps in preparing data for machine learning.

---

## ğŸ“š Libraries Used

- **pandas** â€“ for data manipulation  
- **numpy** â€“ for numerical operations  
- **scikit-learn** â€“ for preprocessing (SimpleImputer, OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler, train_test_split)

---

## ğŸ§¼ Key Steps Performed

### ğŸ”§ Data Preparation

- Imported required libraries  
- Loaded the dataset using `read_csv()`  

### ğŸ“ˆ Handling Missing Values

- Applied `SimpleImputer(strategy='mean')` to fill missing values in numerical columns (`Age`, `Salary`)  
- Used `fit_transform()` to compute and replace missing values  

### ğŸ”¤ Categorical Encoding

#### ğŸ·ï¸ One-Hot Encoding

- Applied `OneHotEncoder(sparse_output=False)` to the `Country` column  
- Used `get_feature_names_out()` to extract meaningful column names  
- Joined encoded columns back to the original dataset  
- Dropped the original `Country` column

#### ğŸ”˜ Label Encoding

- Used `LabelEncoder` on the `Purchased` column to convert Yes/No values into numeric form  
- Applied `fit_transform()` and displayed the result

#### ğŸ“¶ Ordinal Encoding

- Demonstrated ordinal encoding using sample data with an inherent order  
- Used `OrdinalEncoder()` to fit and transform ordered categories  
- Printed the transformed output

---

## âš–ï¸ Feature Scaling

- Applied `StandardScaler` to standardize features by removing the mean and scaling to unit variance  
- Used the formula `z = (x - Î¼) / Ïƒ`  
- Performed:
  - `fit()` â€“ to compute the mean and standard deviation  
  - `transform()` â€“ to apply scaling  
  - `inverse_transform()` â€“ to revert scaled values  
- Displayed scaled output and statistics

---

## ğŸ“‚ Train-Test Split

- Divided the dataset into:
  - **Independent variables** (features)
  - **Dependent variable** (target/output)
- Used `train_test_split()` to split the data into training and testing sets  
- Printed the resulting splits to verify successful separation

---

## âœ… Final Output

- Successfully filled missing values and encoded categorical columns  
- Standardized numerical features for ML compatibility  
- Split dataset into training and testing sets, ready for model development

---

## ğŸ“‚ Files

â”œâ”€â”€ Task-4/
â”‚ â”œâ”€â”€ task-4.ipynb # Notebook with full preprocessing steps
â”‚ â””â”€â”€ README.md # Documentation for Task 4

---

## ğŸ Status

âœ”ï¸ Task 4 completed with full preprocessing  
ğŸ§ª Dataset is now ready for machine learning model training
